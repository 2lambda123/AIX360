{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoFrNet Example Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Imports and Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Seeds\n",
    "\n",
    "from aix360.algorithms.cofrnet.Customized_Linear_Classes import CustomizedLinearFunction\n",
    "from aix360.algorithms.cofrnet.Customized_Linear_Classes import CustomizedLinear\n",
    "from aix360.algorithms.cofrnet.utils import generate_connections\n",
    "from aix360.algorithms.cofrnet.utils import process_data\n",
    "from aix360.algorithms.cofrnet.CoFrNet import CoFrNet_Model\n",
    "from aix360.algorithms.cofrnet.CoFrNet import generate_connections\n",
    "from aix360.algorithms.cofrnet.CoFrNet import CoFrNet_Explainer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "from torch.utils.data import Dataset\n",
    "import torch # import main library\n",
    "import torch.nn as nn # import modules\n",
    "from torch.autograd import Function # import Function to create custom activations\n",
    "from torch.nn.parameter import Parameter # import Parameter to create custom activations with learnable parameters\n",
    "import torch.nn.functional as F # import torch functions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "seed_num = 20\n",
    "random.seed(seed_num)\n",
    "torch.manual_seed(seed_num)\n",
    "np.random.seed(seed_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Setting Up CoFrNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_depth = 13\n",
    "input_size = 40\n",
    "output_size = 3\n",
    "cofrnet_version = \"diag_ladder_of_ladder_combined\"\n",
    "#Create CoFrNet\n",
    "model = CoFrNet_Model(generate_connections(network_depth, \n",
    "                                            input_size, \n",
    "                                            output_size, \n",
    "                                            cofrnet_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data\n",
    "tensor_x_train, tensor_y_train, tensor_x_val, tensor_y_val, tensor_x_test, y_test = process_data(data_filename= 'waveformnoise.csv', \n",
    "                                                                                                first_column_csv = 0, \n",
    "                                                                                                last_column_csv = -1)\n",
    "class OnlyTabularDataset(Dataset):\n",
    "    def __init__(self, values, label):\n",
    "        self.values = values\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'tabular': torch.tensor(self.values[index], dtype=torch.float),\n",
    "            'target' :  torch.tensor(self.label[index], dtype=torch.long)\n",
    "            }\n",
    "\n",
    "train_dataset = OnlyTabularDataset(tensor_x_train, \n",
    "                                    tensor_y_train)\n",
    "\n",
    "dataloader = DataLoader(train_dataset, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    #for i, data in enumerate(trainloader, 0):\n",
    "    for i, batch in tqdm(enumerate(dataloader)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(batch['tabular'])\n",
    "        loss = criterion(outputs, batch['target'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print Accuracies, Continued Fraction, Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = CoFrNet_Explainer(model)\n",
    "explainer.print_accuracy(tensor_x_test, y_test)\n",
    "explainer.importances()\n",
    "explainer.print_co_fr()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
