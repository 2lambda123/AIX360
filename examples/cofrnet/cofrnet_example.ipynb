{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoFrNet Example Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Imports and Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Seeds\n",
    "from Customized_Linear_Classes import CustomizedLinearFunction\n",
    "from Customized_Linear_Classes import CustomizedLinear\n",
    "from utils import generate_connections\n",
    "from utils import process_data\n",
    "from utils import train\n",
    "from utils import OnlyTabularDataset\n",
    "from CoFrNet import CoFrNet_Model\n",
    "from CoFrNet import generate_connections\n",
    "from CoFrNet import CoFrNet_Explainer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "from torch.utils.data import Dataset\n",
    "import torch # import main library\n",
    "import torch.nn as nn # import modules\n",
    "from torch.autograd import Function # import Function to create custom activations\n",
    "from torch.nn.parameter import Parameter # import Parameter to create custom activations with learnable parameters\n",
    "import torch.nn.functional as F # import torch functions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import torch.optim as optim\n",
    "import random\n",
    "import kaggle\n",
    "\n",
    "\n",
    "\n",
    "seed_num = 5\n",
    "random.seed(seed_num)\n",
    "torch.manual_seed(seed_num)\n",
    "np.random.seed(seed_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Setting Up CoFrNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input_size: number of features in your dataset\n",
    "output_size: number of classification categories (number of outputs)\n",
    "cofrnet_version: CoFrNet Variant to be created (see paper for details)\n",
    "network depth: depth of selected CoFrNet Variant. For example, if you select diag_ladder_of_ladder_combined, \n",
    "                the diagonalized section of the network will have depth 13 and the network will explore up to \n",
    "                order 13 interactions. \n",
    "'''\n",
    "network_depth = 13\n",
    "input_size = 10 #10 for telescopeMagic #40 for waveform #23 for creditcard\n",
    "output_size = 2 #2 for telescope #3 for waveform #2 for creditcard\n",
    "cofrnet_version = \"diag_ladder_of_ladder_combined\"\n",
    "#Create CoFrNet\n",
    "model = CoFrNet_Model(generate_connections(network_depth, \n",
    "                                            input_size, \n",
    "                                            output_size, \n",
    "                                            cofrnet_version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Download dataset from Kaggle\n",
    "'''\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "api.dataset_download_files('abhinand05/magic-gamma-telescope-dataset', path=\".\", unzip = True)\n",
    "\n",
    "\n",
    "\n",
    "data_filename= 'telescope_data.csv'\n",
    "first_column_csv = 1\n",
    "last_column_csv = -1\n",
    "\n",
    "\n",
    "'''\n",
    "Use process_data method in utils.py to get tensors for training, validation, testing\n",
    "'''\n",
    "#Get Data\n",
    "tensor_x_train, tensor_y_train, tensor_x_val, tensor_y_val, tensor_x_test, y_test = process_data(data_filename= data_filename, \n",
    "                                                                                                first_column_csv = first_column_csv, \n",
    "                                                                                                last_column_csv = last_column_csv)\n",
    "\n",
    "'''\n",
    "Create a Dataloader\n",
    "'''\n",
    "train_dataset = OnlyTabularDataset(tensor_x_train, \n",
    "                                    tensor_y_train)\n",
    "\n",
    "batch_size = 100\n",
    "dataloader = DataLoader(train_dataset, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use Train Module from Utils to Train\n",
    "'''\n",
    "train(model, dataloader, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print Accuracies, Continued Fraction, Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Print Accuracy of Network\n",
    "'''\n",
    "explainer = CoFrNet_Explainer(model)\n",
    "explainer.print_accuracy(tensor_x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
